"""ä»ç”Ÿäº§ç¯å¢ƒåŒæ­¥è‚¡ç¥¨æ•°æ®åˆ°æœ¬åœ°æ•°æ®åº“ï¼ˆå¢é‡åŒæ­¥ï¼‰"""
import sys
import os
import json
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import pymysql
from pymysql.cursors import DictCursor

# æ·»åŠ é¡¹ç›®è·¯å¾„
backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))

from infrastructure.logging.logger import get_logger

logger = get_logger(__name__)


# å°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼
try:
    from scripts.sync_config import PROD_DB_CONFIG, LOCAL_DB_CONFIG
except ImportError:
    # é»˜è®¤é…ç½®ï¼ˆéœ€è¦ä¿®æ”¹ï¼‰
    PROD_DB_CONFIG = {
        'host': 'ç”Ÿäº§ç¯å¢ƒIP',  # è¯·ä¿®æ”¹ä¸ºå®é™…çš„ç”Ÿäº§ç¯å¢ƒIP
        'port': 3306,
        'user': 'ç”Ÿäº§ç¯å¢ƒç”¨æˆ·å',  # è¯·ä¿®æ”¹ä¸ºå®é™…çš„ç”¨æˆ·å
        'password': 'ç”Ÿäº§ç¯å¢ƒå¯†ç ',  # è¯·ä¿®æ”¹ä¸ºå®é™…çš„å¯†ç 
        'database': 'stock',  # æ•°æ®åº“å
        'charset': 'utf8mb4'
    }
    
    # æœ¬åœ°æ•°æ®åº“é…ç½®ï¼ˆä»config.pyè¯»å–ï¼‰
    try:
        import sys
        root_dir = Path(__file__).parent.parent.parent
        sys.path.insert(0, str(root_dir))
        from config import DATABASE_CONFIG
        LOCAL_DB_CONFIG = DATABASE_CONFIG
    except ImportError:
        LOCAL_DB_CONFIG = {
            'host': 'localhost',
            'port': 3306,
            'user': 'root',
            'password': '1234',
            'database': 'stock',
            'charset': 'utf8mb4'
        }

# å‘¨æœŸç±»å‹æ˜ å°„
PERIOD_TYPE_MAP = {
    '30min': '30min',
    'day': '1day',
    'week': '1week',
    'month': '1month'
}


def load_stock_config() -> Dict[str, List[Dict]]:
    """åŠ è½½è‚¡ç¥¨é…ç½®æ–‡ä»¶"""
    config_path = backend_dir / 'infrastructure' / 'config' / 'stock_config.json'
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def get_all_table_names() -> List[str]:
    """è·å–æ‰€æœ‰è‚¡ç¥¨è¡¨å"""
    config = load_stock_config()
    table_names = []
    for stocks in config.values():
        for stock in stocks:
            table_name = stock.get('table')
            if table_name and table_name not in table_names:
                table_names.append(table_name)
    return table_names


def get_local_max_time(conn, table_name: str, period_code: str) -> Optional[datetime]:
    """è·å–æœ¬åœ°æ•°æ®åº“ä¸­æŒ‡å®šè¡¨å’Œå‘¨æœŸçš„æœ€å¤§æ—¶é—´"""
    try:
        cursor = conn.cursor(DictCursor)
        query = f"""
            SELECT MAX(shi_jian) as max_time
            FROM {table_name}
            WHERE peroid_type = %s
        """
        cursor.execute(query, (period_code,))
        result = cursor.fetchone()
        cursor.close()
        
        if result and result.get('max_time'):
            return result['max_time']
        return None
    except Exception as e:
        logger.warning(f"è·å–æœ¬åœ°æœ€å¤§æ—¶é—´å¤±è´¥: {table_name}, {period_code}, é”™è¯¯={str(e)}")
        return None


def sync_table_data(
    prod_conn,
    local_conn,
    table_name: str,
    period_type: str,
    period_code: str,
    batch_size: int = 1000
) -> int:
    """
    åŒæ­¥å•ä¸ªè¡¨çš„æ•°æ®
    
    Args:
        prod_conn: ç”Ÿäº§ç¯å¢ƒæ•°æ®åº“è¿æ¥
        local_conn: æœ¬åœ°æ•°æ®åº“è¿æ¥
        table_name: è¡¨å
        period_type: å‘¨æœŸç±»å‹ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        period_code: å‘¨æœŸä»£ç ï¼ˆæ•°æ®åº“ä¸­çš„å€¼ï¼‰
        batch_size: æ‰¹é‡æ’å…¥å¤§å°
        
    Returns:
        åŒæ­¥çš„è®°å½•æ•°
    """
    try:
        # è·å–æœ¬åœ°æœ€å¤§æ—¶é—´
        local_max_time = get_local_max_time(local_conn, table_name, period_code)
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        if local_max_time:
            # å¢é‡åŒæ­¥ï¼šåªåŒæ­¥å¤§äºæœ¬åœ°æœ€å¤§æ—¶é—´çš„æ•°æ®
            start_time = local_max_time
            logger.info(f"å¢é‡åŒæ­¥ {table_name} {period_type}: ä» {start_time} å¼€å§‹")
        else:
            # å…¨é‡åŒæ­¥ï¼šåŒæ­¥æœ€è¿‘2å¹´çš„æ•°æ®
            start_time = datetime.now() - timedelta(days=730)
            logger.info(f"å…¨é‡åŒæ­¥ {table_name} {period_type}: ä» {start_time} å¼€å§‹")
        
        # ä»ç”Ÿäº§ç¯å¢ƒæŸ¥è¯¢æ•°æ®
        prod_cursor = prod_conn.cursor(DictCursor)
        query = f"""
            SELECT shi_jian, kai_pan_jia, zui_gao_jia, zui_di_jia, shou_pan_jia,
                   cheng_jiao_liang, liang_bi, wei_bi, peroid_type
            FROM {table_name}
            WHERE peroid_type = %s AND shi_jian > %s
            ORDER BY shi_jian ASC
        """
        prod_cursor.execute(query, (period_code, start_time))
        
        # æ‰¹é‡æ’å…¥åˆ°æœ¬åœ°æ•°æ®åº“
        local_cursor = local_conn.cursor()
        # ä½¿ç”¨ INSERT IGNORE æˆ– ON DUPLICATE KEY UPDATE
        # å‡è®¾è¡¨æœ‰åŸºäº (shi_jian, peroid_type) çš„å”¯ä¸€ç´¢å¼•
        insert_query = f"""
            INSERT INTO {table_name} 
            (shi_jian, kai_pan_jia, zui_gao_jia, zui_di_jia, shou_pan_jia,
             cheng_jiao_liang, liang_bi, wei_bi, peroid_type)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON DUPLICATE KEY UPDATE
                kai_pan_jia = VALUES(kai_pan_jia),
                zui_gao_jia = VALUES(zui_gao_jia),
                zui_di_jia = VALUES(zui_di_jia),
                shou_pan_jia = VALUES(shou_pan_jia),
                cheng_jiao_liang = VALUES(cheng_jiao_liang),
                liang_bi = VALUES(liang_bi),
                wei_bi = VALUES(wei_bi)
        """
        
        count = 0
        batch = []
        
        while True:
            rows = prod_cursor.fetchmany(batch_size)
            if not rows:
                break
            
            for row in rows:
                batch.append((
                    row['shi_jian'],
                    row['kai_pan_jia'],
                    row['zui_gao_jia'],
                    row['zui_di_jia'],
                    row['shou_pan_jia'],
                    row['cheng_jiao_liang'],
                    row['liang_bi'],
                    row['wei_bi'],
                    row['peroid_type']
                ))
                
                if len(batch) >= batch_size:
                    local_cursor.executemany(insert_query, batch)
                    local_conn.commit()
                    count += len(batch)
                    logger.debug(f"å·²åŒæ­¥ {table_name} {period_type}: {count} æ¡è®°å½•")
                    batch = []
            
            if batch:
                local_cursor.executemany(insert_query, batch)
                local_conn.commit()
                count += len(batch)
                batch = []
        
        prod_cursor.close()
        local_cursor.close()
        
        if count > 0:
            logger.info(f"âœ… åŒæ­¥å®Œæˆ {table_name} {period_type}: {count} æ¡æ–°è®°å½•")
        else:
            logger.info(f"â„¹ï¸  {table_name} {period_type}: æ— æ–°æ•°æ®")
        
        return count
        
    except Exception as e:
        logger.error(f"âŒ åŒæ­¥å¤±è´¥ {table_name} {period_type}: {str(e)}", exc_info=True)
        return 0


def check_table_exists(conn, table_name: str) -> bool:
    """æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨"""
    try:
        cursor = conn.cursor()
        cursor.execute(f"SHOW TABLES LIKE '{table_name}'")
        result = cursor.fetchone()
        cursor.close()
        return result is not None
    except Exception as e:
        logger.error(f"æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨å¤±è´¥: {table_name}, é”™è¯¯={str(e)}")
        return False


def sync_all_stocks():
    """åŒæ­¥æ‰€æœ‰è‚¡ç¥¨æ•°æ®"""
    logger.info("=" * 60)
    logger.info("å¼€å§‹åŒæ­¥è‚¡ç¥¨æ•°æ®ï¼ˆä»ç”Ÿäº§ç¯å¢ƒåˆ°æœ¬åœ°ï¼‰")
    logger.info("=" * 60)
    
    # è¿æ¥æ•°æ®åº“
    try:
        logger.info("æ­£åœ¨è¿æ¥ç”Ÿäº§ç¯å¢ƒæ•°æ®åº“...")
        prod_conn = pymysql.connect(**PROD_DB_CONFIG)
        logger.info("âœ… ç”Ÿäº§ç¯å¢ƒæ•°æ®åº“è¿æ¥æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ ç”Ÿäº§ç¯å¢ƒæ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
        return
    
    try:
        logger.info("æ­£åœ¨è¿æ¥æœ¬åœ°æ•°æ®åº“...")
        local_conn = pymysql.connect(**LOCAL_DB_CONFIG)
        logger.info("âœ… æœ¬åœ°æ•°æ®åº“è¿æ¥æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ æœ¬åœ°æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
        prod_conn.close()
        return
    
    try:
        # è·å–æ‰€æœ‰è¡¨å
        table_names = get_all_table_names()
        logger.info(f"æ‰¾åˆ° {len(table_names)} ä¸ªè‚¡ç¥¨è¡¨éœ€è¦åŒæ­¥")
        
        # æ”¯æŒçš„å‘¨æœŸç±»å‹
        periods = ['30min', 'day', 'week', 'month']
        
        total_synced = 0
        total_tables = 0
        
        # éå†æ¯ä¸ªè¡¨
        for table_name in table_names:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            if not check_table_exists(prod_conn, table_name):
                logger.warning(f"âš ï¸  ç”Ÿäº§ç¯å¢ƒè¡¨ä¸å­˜åœ¨: {table_name}ï¼Œè·³è¿‡")
                continue
            
            if not check_table_exists(local_conn, table_name):
                logger.warning(f"âš ï¸  æœ¬åœ°è¡¨ä¸å­˜åœ¨: {table_name}ï¼Œè·³è¿‡")
                continue
            
            logger.info(f"\nğŸ“Š å¼€å§‹åŒæ­¥è¡¨: {table_name}")
            
            # åŒæ­¥æ¯ä¸ªå‘¨æœŸ
            for period_type in periods:
                period_code = PERIOD_TYPE_MAP[period_type]
                count = sync_table_data(
                    prod_conn,
                    local_conn,
                    table_name,
                    period_type,
                    period_code
                )
                total_synced += count
                if count > 0:
                    total_tables += 1
        
        logger.info("\n" + "=" * 60)
        logger.info(f"åŒæ­¥å®Œæˆï¼")
        logger.info(f"å…±åŒæ­¥ {total_synced} æ¡è®°å½•ï¼Œæ¶‰åŠ {total_tables} ä¸ªè¡¨/å‘¨æœŸç»„åˆ")
        logger.info("=" * 60)
        
    finally:
        prod_conn.close()
        local_conn.close()
        logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")


if __name__ == '__main__':
    # æ£€æŸ¥é…ç½®
    if PROD_DB_CONFIG.get('host') in ['ç”Ÿäº§ç¯å¢ƒIP', '192.168.1.100'] or not PROD_DB_CONFIG.get('host'):
        print("=" * 60)
        print("âš ï¸  è­¦å‘Šï¼šè¯·å…ˆé…ç½®ç”Ÿäº§ç¯å¢ƒæ•°æ®åº“è¿æ¥ä¿¡æ¯ï¼")
        print("=" * 60)
        print("è¯·åˆ›å»ºé…ç½®æ–‡ä»¶ backend/scripts/sync_config.py")
        print("å‚è€ƒ sync_config_example.py æ–‡ä»¶")
        print("=" * 60)
        sys.exit(1)
    
    print("=" * 60)
    print(f"ç”Ÿäº§ç¯å¢ƒ: {PROD_DB_CONFIG['host']}:{PROD_DB_CONFIG['port']}")
    print(f"æœ¬åœ°ç¯å¢ƒ: {LOCAL_DB_CONFIG['host']}:{LOCAL_DB_CONFIG['port']}")
    print("=" * 60)
    
    sync_all_stocks()

